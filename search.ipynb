{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise Static Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Values\n",
    "\n",
    "romania_map = {\n",
    "    'Arad': [('Zerind', 75), ('Sibiu', 140), ('Timisoara', 118)],\n",
    "    'Zerind': [('Oradea', 71), ('Arad', 75)],\n",
    "    'Oradea': [('Zerind', 71), ('Sibiu', 151)],\n",
    "    'Sibiu': [('Oradea', 151), ('Arad', 140), ('Fagaras', 99), ('Rimnicu Vilcea', 80)],\n",
    "    'Timisoara': [('Arad', 118), ('Lugoj', 111)],\n",
    "    'Lugoj': [('Timisoara', 111), ('Mehadia', 70)],\n",
    "    'Mehadia': [('Lugoj', 70), ('Drobeta', 75)],\n",
    "    'Drobeta': [('Mehadia', 75), ('Craiova', 120)],\n",
    "    'Craiova': [('Drobeta', 120), ('Rimnicu Vilcea', 146), ('Pitesti', 138)],\n",
    "    'Rimnicu Vilcea': [('Sibiu', 80), ('Craiova', 146), ('Pitesti', 97)],\n",
    "    'Pitesti': [('Rimnicu Vilcea', 97), ('Craiova', 138), ('Bucharest', 101)],\n",
    "    'Fagaras': [('Sibiu', 99), ('Bucharest', 211)],\n",
    "    'Bucharest': [('Fagaras', 211), ('Pitesti', 101), ('Giurgiu', 90), ('Urziceni', 85)],\n",
    "    'Giurgiu': [('Bucharest', 90)],\n",
    "    'Urziceni': [('Bucharest', 85), ('Hirsova', 98), ('Vaslui', 142)],\n",
    "    'Hirsova': [('Urziceni', 98), ('Eforie', 86)],\n",
    "    'Eforie': [('Hirsova', 86)],\n",
    "    'Vaslui': [('Urziceni', 142), ('Iasi', 92)],\n",
    "    'Iasi': [('Vaslui', 92), ('Neamt', 87)],\n",
    "    'Neamt': [('Iasi', 87)]\n",
    "}\n",
    "\n",
    "# Straight Line Distances from each city to Bucharest\n",
    "sld_to_bucharest = {\n",
    "    'Arad': 366, 'Bucharest': 0, 'Craiova': 160, 'Drobeta': 242, 'Eforie': 161,\n",
    "    'Fagaras': 176, 'Giurgiu': 77, 'Hirsova': 151, 'Iasi': 226, 'Lugoj': 244,\n",
    "    'Mehadia': 241, 'Neamt': 234, 'Oradea': 380, 'Pitesti': 100, 'Rimnicu Vilcea': 193,\n",
    "    'Sibiu': 253, 'Timisoara': 329, 'Urziceni': 80, 'Vaslui': 199, 'Zerind': 374\n",
    "}\n",
    "\n",
    "# Romania's cities and their positions\n",
    "romania_map_coordinates = {\n",
    "    'A' : {'pos': (21.31227,46.18656), 'connections': ['S','T','Z'] },\n",
    "    'S' : {'pos': (24.12558,45.79833), 'connections': ['F','RV','O'] },\n",
    "    'Z' : {'pos': (21.51742,46.62251), 'connections': ['O'] },\n",
    "    'T' : {'pos': (21.20868,45.74887), 'connections': ['L'] },\n",
    "    'O' : {'pos': (21.91894,47.04650), 'connections': [] },\n",
    "    'F' : {'pos': (24.97310,45.84164), 'connections': ['B'] },\n",
    "    'L' : {'pos': (21.90346,45.69099), 'connections': ['M'] },\n",
    "    'RV' : {'pos': (24.36932,45.09968), 'connections': ['C','P'] },\n",
    "    'M' : {'pos': (22.36452,44.90411), 'connections': ['D'] },\n",
    "    'D' : {'pos': (22.65973,44.63692), 'connections': ['C'] },\n",
    "    'C' : {'pos': (23.79488,44.33018), 'connections': [] },\n",
    "    'P' : {'pos': (24.86918,44.85648), 'connections': ['B','C'] },\n",
    "    'B' : {'pos': (26.10254,44.42677), 'connections': ['G','U'] },\n",
    "    'G' : {'pos': (25.96993,43.90371), 'connections': [] },\n",
    "    'U' : {'pos': (26.64112,44.71653), 'connections': ['H','V'] },\n",
    "    'V' : {'pos': (27.72765,46.64069), 'connections': ['I'] },\n",
    "    'I' : {'pos': (27.60144,47.15845), 'connections': ['N'] },\n",
    "    'N' : {'pos': (26.38188,46.97587), 'connections': [] },\n",
    "    'H' : {'pos': (27.94566,44.68935), 'connections': ['E'] },\n",
    "    'E' : {'pos': (28.65273,44.04911), 'connections': [] }\n",
    "}\n",
    "# Reference - plot graph coordinates: https://gist.github.com/parthi2929/27168746d6bfe10a350227c277b2a9c8#file-romania_helper_ipython-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Plotting Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Calculate distances between two cities\n",
    "def calculate_distance(pos1, pos2):\n",
    "    return round(geodesic((pos1[1], pos1[0]), (pos2[1], pos2[0])).kilometers, 2)\n",
    "\n",
    "# Create the graph and add distances as edge labels\n",
    "def load_map_graph_with_distances(map_dict):\n",
    "    G = nx.Graph()\n",
    "    for city, data in map_dict.items():\n",
    "        G.add_node(city, pos=data['pos'])\n",
    "        for neighbor in data['connections']:\n",
    "            distance = calculate_distance(map_dict[city]['pos'], map_dict[neighbor]['pos'])\n",
    "            G.add_edge(city, neighbor, weight=distance)\n",
    "    return G\n",
    "\n",
    "# Function to plot the graph with highlighted path and distances\n",
    "def plot_graph_with_path_and_distances(G, path=None):\n",
    "    pos = nx.get_node_attributes(G, 'pos')  # Extract positions\n",
    "    plt.figure(figsize=(6, 5))\n",
    "\n",
    "    # Draw the entire graph\n",
    "    nx.draw(G, pos, node_color='skyblue', with_labels=True, node_size=500, font_size=10, font_weight='bold', font_color='black')\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray')\n",
    "\n",
    "    # Draw edge labels (distances)\n",
    "    edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size = 8, font_color='green', verticalalignment='bottom')\n",
    "\n",
    "    # Highlight the path if provided\n",
    "    if path:\n",
    "        # Highlight the nodes in the path\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=path, node_color='red', node_size=500)\n",
    "\n",
    "        # Highlight the edges in the path\n",
    "        path_edges = list(zip(path, path[1:]))\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=path_edges, edge_color='red', width=2)\n",
    "\n",
    "    plt.title('Romania Map with Highlighted Path and Distances')\n",
    "    plt.show()\n",
    "\n",
    "G = load_map_graph_with_distances(romania_map_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searches:\n",
    "\n",
    "1. Breadth First Search\n",
    "2. Depth First Search\n",
    "3. Greedy Best First Search\n",
    "4. A* Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import time\n",
    "import tracemalloc\n",
    "import pandas as pd\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Estimate SLD to Goal City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sld_to_goal_city(goal_city):\n",
    "    if goal_city not in sld_to_bucharest:\n",
    "        raise ValueError(f\"SLD information for {goal_city} is not available\")\n",
    "\n",
    "    sld_goal_city_to_bucharest = sld_to_bucharest[goal_city]\n",
    "    estimated_sld = {city: (sld_to_bucharest[city] + sld_goal_city_to_bucharest\n",
    "                            if city != goal_city else 0)\n",
    "                        for city in sld_to_bucharest}\n",
    "    return estimated_sld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Romania Map format for BFS and A Star Search Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_map_format(romania_map):\n",
    "    romania_map_convert = {}\n",
    "\n",
    "    for city, connections in romania_map.items():\n",
    "        romania_map_convert[city] = {}\n",
    "        for destination, distance in connections:\n",
    "            romania_map_convert[city][destination] = distance\n",
    "\n",
    "    return romania_map_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Total Distances (For BFS and DFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_distance(path, graph_distance):\n",
    "    total_distance = 0\n",
    "    for i in range(len(path) - 1):\n",
    "        city, next_city = path[i], path[i + 1]\n",
    "        for neighbor, distance in graph_distance[city]:\n",
    "            if neighbor == next_city:\n",
    "                total_distance += distance\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"No direct route from {city} to {next_city}\")\n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Breadth First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breadth_first_search(graph, start, goal):\n",
    "    \"\"\"Performs BFS on the graph from start to goal.\"\"\"\n",
    "    # Queue for BFS (deque for efficient pop from the front)\n",
    "    frontier = deque([start])\n",
    "\n",
    "    # Track explored nodes and the path\n",
    "    explored = set()\n",
    "    path = {start: None}\n",
    "\n",
    "    # Node expansion count (to keep track of performance)\n",
    "    node_expansion_count = 0\n",
    "\n",
    "    while frontier:\n",
    "        # Pop the first node in the frontier\n",
    "        node = frontier.popleft()\n",
    "        node_expansion_count += 1  # Increment node expansion count when a node is dequeued\n",
    "\n",
    "        # If we reach the goal, return the path\n",
    "        if node == goal:\n",
    "            return construct_bfs_path(path, start, goal), node_expansion_count\n",
    "\n",
    "        explored.add(node)\n",
    "\n",
    "        # Explore neighbors\n",
    "        for neighbor in graph[node]:\n",
    "            if neighbor not in explored and neighbor not in frontier:\n",
    "                path[neighbor] = node\n",
    "                frontier.append(neighbor)\n",
    "\n",
    "    return None, node_expansion_count  # Return no path if goal is not found\n",
    "\n",
    "def construct_bfs_path(path, start, goal):\n",
    "    \"\"\"Reconstruct the path from the BFS search.\"\"\"\n",
    "    route = []\n",
    "    node = goal\n",
    "    while node is not None:\n",
    "        route.append(node)\n",
    "        node = path[node]\n",
    "    route.reverse()\n",
    "    return route\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Depth First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_search(graph, start, goal):\n",
    "    stack = [(start, [start])]\n",
    "    visited = set()\n",
    "    node_expansions = 0  # Counter to track the number of node expansions\n",
    "\n",
    "    while stack:\n",
    "        current_city, path = stack.pop()\n",
    "        if current_city not in visited:\n",
    "            visited.add(current_city)\n",
    "            node_expansions += 1  # Increment the counter when a node is expanded\n",
    "            \n",
    "            if current_city == goal:\n",
    "                return path, node_expansions  # Return the path and node expansions\n",
    "            \n",
    "            for neighbor, _ in graph[current_city]:\n",
    "                if neighbor not in visited:\n",
    "                    stack.append((neighbor, path + [neighbor]))\n",
    "\n",
    "    return None, node_expansions  # In case the goal is not reached, return the node expansions anyway\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(graph, start, goal, heuristic):\n",
    "    priority_queue = []\n",
    "    heapq.heappush(priority_queue, (heuristic[start], start, [start], 0))\n",
    "    explored = set()\n",
    "    node_expansions = 0  # Counter to track the number of node expansions\n",
    "\n",
    "    while priority_queue:\n",
    "        h_value, current_city, path, traveled_distance = heapq.heappop(priority_queue)\n",
    "        \n",
    "        node_expansions += 1  # Increment the counter each time a node is expanded\n",
    "\n",
    "        if current_city == goal:\n",
    "            return path, traveled_distance, node_expansions  # Return path, distance, and node expansions\n",
    "\n",
    "        explored.add(current_city)\n",
    "\n",
    "        for neighbor, distance in graph[current_city]:\n",
    "            if neighbor not in explored:\n",
    "                new_traveled_distance = traveled_distance + distance\n",
    "                heapq.heappush(priority_queue, (heuristic[neighbor], neighbor, path + [neighbor], new_traveled_distance))\n",
    "\n",
    "    return [], float('inf'), node_expansions  # Return node expansions even if goal is not found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. A Star Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star_search_with_multiple_heuristics(graph, start, goal, estimate_sld_to_goal_city_dict, heuristic_type='sld', intermediary='Bucharest'):\n",
    "    # Track node expansion\n",
    "    node_expansion_count = 0\n",
    "\n",
    "    # Initialize frontier (priority queue) and other variables\n",
    "    def heuristic(city, goal):\n",
    "        if heuristic_type == 'sld':  # Straight-line distance heuristic\n",
    "            return estimate_sld_to_goal_city_dict.get(city, float('inf'))\n",
    "        elif heuristic_type == 'triangle':  # Triangle inequality heuristic\n",
    "            return abs(estimate_sld_to_goal_city_dict.get(city, float('inf')) - estimate_sld_to_goal_city_dict.get(goal, float('inf')))\n",
    "\n",
    "    frontier = [(0 + heuristic(start, goal), start)]\n",
    "    heapq.heapify(frontier)  # Priority queue (min-heap)\n",
    "    explored = set()\n",
    "    g_costs = {start: 0}\n",
    "    path = {start: None}\n",
    "\n",
    "    while frontier:\n",
    "        _, node = heapq.heappop(frontier)\n",
    "        node_expansion_count += 1  # Increment node expansion count when a node is dequeued\n",
    "\n",
    "        if node == goal:\n",
    "            return construct_path(path, start, goal), g_costs[goal], node_expansion_count  # Return the path, cost, and node expansion\n",
    "\n",
    "        explored.add(node)\n",
    "\n",
    "        for neighbor, cost in graph[node].items():\n",
    "            tentative_g = g_costs[node] + cost\n",
    "            if neighbor not in explored or tentative_g < g_costs.get(neighbor, float('inf')):\n",
    "                g_costs[neighbor] = tentative_g\n",
    "                f_cost = tentative_g + heuristic(neighbor, goal)\n",
    "                heapq.heappush(frontier, (f_cost, neighbor))\n",
    "                path[neighbor] = node\n",
    "\n",
    "    return None, float('inf'), node_expansion_count  # Return no path and infinite cost if goal not found\n",
    "\n",
    "def construct_path(path, start, goal):\n",
    "    \"\"\"Helper function to reconstruct the path from start to goal.\"\"\"\n",
    "    route = []\n",
    "    node = goal\n",
    "    while node is not None:\n",
    "        route.append(node)\n",
    "        node = path[node]\n",
    "    route.reverse()\n",
    "    return route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_search_performance(search, start, goal, plot_graph=False):\n",
    "    \"\"\"\n",
    "    Analyzes the performance of different search algorithms (BFS, DFS, Greedy, A*) on the Romanian road map.\n",
    "    \n",
    "    Parameters:\n",
    "    search (str): The search algorithm to be used. Options are \"bfs\", \"dfs\", \"greedy\", and \"a_star\".\n",
    "    start (str): The starting city.\n",
    "    goal (str): The goal city.\n",
    "    plot_graph (bool): True or False\n",
    "\n",
    "    Returns:\n",
    "    None: Prints the path, nodes expanded, execution time, total distance, and memory usage.\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    output['search'] = search\n",
    "\n",
    "    # Convert map to the appropriate format (e.g., adjacency list or matrix) if needed for BFS and A* algorithms\n",
    "    if search in [\"bfs\", \"a_star\"]:\n",
    "        graph = convert_map_format(romania_map)\n",
    "    else:\n",
    "        graph = romania_map\n",
    "    \n",
    "    # Estimate the straight-line distances (SLD) to the goal for Greedy and A* algorithms\n",
    "    if search in [\"greedy\", \"a_star\"]:\n",
    "        estimate_sld_to_goal_city_dict = estimate_sld_to_goal_city(goal)\n",
    "\n",
    "    # Start tracking memory usage and execution time\n",
    "    tracemalloc.start()\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Perform the specified search algorithm and calculate the path and distance\n",
    "    if search == \"bfs\":\n",
    "        # Perform Breadth-First Search\n",
    "        output['path'], output['nodes'] = breadth_first_search(graph, start, goal)\n",
    "        output['distance_in_kms'] = calculate_total_distance(output['path'], romania_map)\n",
    "    elif search == \"dfs\":\n",
    "        # Perform Depth-First Search\n",
    "        output['path'], output['nodes'] = depth_first_search(graph, start, goal)\n",
    "        output['distance_in_kms'] = calculate_total_distance(output['path'], romania_map)\n",
    "    elif search == \"greedy\":\n",
    "        # Perform Greedy Search (best-first search using heuristics)\n",
    "        output['path'], output['distance_in_kms'], output['nodes'] = greedy_search(graph, start, goal, estimate_sld_to_goal_city_dict)\n",
    "    elif search == \"a_star\":\n",
    "        # Perform A* Search with multiple heuristics\n",
    "        output['path'], output['distance_in_kms'], output['nodes'] = a_star_search_with_multiple_heuristics(graph, start, goal, estimate_sld_to_goal_city_dict)\n",
    "\n",
    "    # Get the initials of the cities in the path for visualization purposes\n",
    "    output['path_letters'] = [''.join(word[0] for word in city.split()) for city in output['path']]\n",
    "\n",
    "    # Measure execution time\n",
    "    end_time = time.time()\n",
    "    output['execution_time'] = end_time - start_time\n",
    "\n",
    "    # Measure memory usage\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    output['current'], output['peak'] = current/10**6, peak/10**6\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    print_flag = False\n",
    "    if print_flag:\n",
    "        # Output the results\n",
    "        print(f\"{search.upper()} Search Results:\")\n",
    "        print(f\"Path: {output['path']}\")  # The full path from start to goal\n",
    "        print(f\"Path Letters: {output['path_letters']}\")  # Abbreviated city names for visualization\n",
    "        print(f\"Nodes Expanded: {output['nodes']}\")  # Number of nodes expanded during the search\n",
    "        print(f\"Total Distance: {output['distance_in_kms']} km\")  # Total distance of the path in kilometers\n",
    "        print(f\"Execution Time: {output['execution_time']:.6f} seconds\")  # Time taken to complete the search\n",
    "        print(f\"Current Memory Usage: {output['current']} MB\")  # Memory currently being used\n",
    "        print(f\"Peak Memory Usage: {output['peak']} MB\")  # Peak memory usage during the search\n",
    "\n",
    "    if plot_graph:\n",
    "        # Plot the graph with the path and distances for visual representation\n",
    "        print(f\"{search} Search\")\n",
    "        plot_graph_with_path_and_distances(G, output['path_letters'])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>search</th>\n",
       "      <th>path</th>\n",
       "      <th>nodes</th>\n",
       "      <th>distance_in_kms</th>\n",
       "      <th>path_letters</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>current</th>\n",
       "      <th>peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bfs</td>\n",
       "      <td>[Arad, Sibiu, Fagaras, Bucharest]</td>\n",
       "      <td>9</td>\n",
       "      <td>450</td>\n",
       "      <td>[A, S, F, B]</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dfs</td>\n",
       "      <td>[Arad, Timisoara, Lugoj, Mehadia, Drobeta, Cra...</td>\n",
       "      <td>8</td>\n",
       "      <td>733</td>\n",
       "      <td>[A, T, L, M, D, C, P, B]</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greedy</td>\n",
       "      <td>[Arad, Sibiu, Fagaras, Bucharest]</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "      <td>[A, S, F, B]</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a_star</td>\n",
       "      <td>[Arad, Sibiu, Rimnicu Vilcea, Pitesti, Bucharest]</td>\n",
       "      <td>6</td>\n",
       "      <td>418</td>\n",
       "      <td>[A, S, RV, P, B]</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   search                        path                         nodes  \\\n",
       "0     bfs                  [Arad, Sibiu, Fagaras, Bucharest]    9     \n",
       "1     dfs  [Arad, Timisoara, Lugoj, Mehadia, Drobeta, Cra...    8     \n",
       "2  greedy                  [Arad, Sibiu, Fagaras, Bucharest]    4     \n",
       "3  a_star  [Arad, Sibiu, Rimnicu Vilcea, Pitesti, Bucharest]    6     \n",
       "\n",
       "   distance_in_kms        path_letters        execution_time  current   peak   \n",
       "0        450                    [A, S, F, B]      0.0013      0.0004   0.0025  \n",
       "1        733        [A, T, L, M, D, C, P, B]      0.0023      0.0016   0.0023  \n",
       "2        450                    [A, S, F, B]      0.0010      0.0003   0.0010  \n",
       "3        418                [A, S, RV, P, B]      0.0012      0.0005   0.0026  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 'Arad'\n",
    "goal = 'Bucharest'\n",
    "plot_graph = False\n",
    "bfs_output = analyze_search_performance('bfs', start, goal, plot_graph)\n",
    "dfs_output = analyze_search_performance('dfs', start, goal, plot_graph)\n",
    "greedy_output = analyze_search_performance('greedy', start, goal, plot_graph)\n",
    "a_star_output = analyze_search_performance('a_star', start, goal, plot_graph)\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame([bfs_output, dfs_output, greedy_output, a_star_output])\n",
    "# Display the DataFrame\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 100 iterations for each algorithm for each and every start,goal city combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Execution Times after 100 iterations:\n",
      "Average BFS Time: 0.232549 seconds\n",
      "Average DFS Time: 0.318018 seconds\n",
      "Average Greedy Time: 0.251728 seconds\n",
      "Average A* Time: 0.310134 seconds\n"
     ]
    }
   ],
   "source": [
    "plot_graph = False\n",
    "iterations = 100\n",
    "bfs_time = []\n",
    "dfs_time = []\n",
    "greedy_time = []\n",
    "a_star_time = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    for start in romania_map.keys():\n",
    "        for goal in romania_map.keys():\n",
    "            bfs_output = analyze_search_performance('bfs', start, goal, plot_graph)\n",
    "    bfs_time.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for start in romania_map.keys():\n",
    "        for goal in romania_map.keys():\n",
    "            dfs_output = analyze_search_performance('dfs', start, goal, plot_graph)\n",
    "    dfs_time.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for start in romania_map.keys():\n",
    "        for goal in romania_map.keys():\n",
    "            greedy_output = analyze_search_performance('greedy', start, goal, plot_graph)\n",
    "    greedy_time.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for start in romania_map.keys():\n",
    "        for goal in romania_map.keys():\n",
    "            a_star_output = analyze_search_performance('a_star', start, goal, plot_graph)\n",
    "    a_star_time.append(time.time() - start_time)\n",
    "\n",
    "# Calculate average execution time for each algorithm\n",
    "avg_bfs_time = sum(bfs_time) / iterations\n",
    "avg_dfs_time = sum(dfs_time) / iterations\n",
    "avg_greedy_time = sum(greedy_time) / iterations\n",
    "avg_a_star_time = sum(a_star_time) / iterations\n",
    "\n",
    "# Display average times\n",
    "print(f\"Average Execution Times after {iterations} iterations:\")\n",
    "print(f\"Average BFS Time: {avg_bfs_time:.6f} seconds\")\n",
    "print(f\"Average DFS Time: {avg_dfs_time:.6f} seconds\")\n",
    "print(f\"Average Greedy Time: {avg_greedy_time:.6f} seconds\")\n",
    "print(f\"Average A* Time: {avg_a_star_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 10000 iterations for each algorithm for one start-goal city combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Execution Times after 10000 iterations:\n",
      "Average BFS Time: 0.000148 seconds. Total BFS Time: 1.4835550785064697\n",
      "Average DFS Time: 0.000136 seconds. Total DFS Time: 1.3609087467193604\n",
      "Average Greedy Time: 0.000136 seconds. Total Greedy Time 1.3616154193878174\n",
      "Average A* Time: 0.000159 seconds. Total A* Time 1.590754508972168\n"
     ]
    }
   ],
   "source": [
    "plot_graph = False\n",
    "iterations = 10000\n",
    "bfs_time = []\n",
    "dfs_time = []\n",
    "greedy_time = []\n",
    "a_star_time = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    bfs_output = analyze_search_performance('bfs', start, goal, plot_graph)\n",
    "    bfs_time.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    dfs_output = analyze_search_performance('dfs', start, goal, plot_graph)\n",
    "    dfs_time.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    greedy_output = analyze_search_performance('greedy', start, goal, plot_graph)\n",
    "    greedy_time.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    a_star_output = analyze_search_performance('a_star', start, goal, plot_graph)\n",
    "    a_star_time.append(time.time() - start_time)\n",
    "\n",
    "# Calculate average execution time for each algorithm\n",
    "avg_bfs_time = sum(bfs_time) / iterations\n",
    "avg_dfs_time = sum(dfs_time) / iterations\n",
    "avg_greedy_time = sum(greedy_time) / iterations\n",
    "avg_a_star_time = sum(a_star_time) / iterations\n",
    "\n",
    "# Display average times\n",
    "print(f\"Average Execution Times after {iterations} iterations:\")\n",
    "print(f\"Average BFS Time: {avg_bfs_time:.6f} seconds. Total BFS Time: {sum(bfs_time)}\")\n",
    "print(f\"Average DFS Time: {avg_dfs_time:.6f} seconds. Total DFS Time: {sum(dfs_time)}\")\n",
    "print(f\"Average Greedy Time: {avg_greedy_time:.6f} seconds. Total Greedy Time {sum(greedy_time)}\")\n",
    "print(f\"Average A* Time: {avg_a_star_time:.6f} seconds. Total A* Time {sum(a_star_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity Analysis:\n",
    "\n",
    "1. Breadth-First Search:\\\n",
    "        - Time Complexity: O(b<sup>d</sup>) where b is branching factor and d is depth of the shallowest solution.\\\n",
    "        - Space Complexity: O(b<sup>d</sup>) because it stores all nodes in memory.\n",
    "\n",
    "2. Depth-First Search:\\\n",
    "        - Time Complexity: O(b<sup>d</sup>) where b is branching factor and d is the maximum depth of the search space. DFS explores as deep as possible into the tree before backtracking, so in the worst case, it may traverse the entire tree up to the maximum depth.\\\n",
    "        - Space Complexity: O(b<sup>d</sup>) because it stores all nodes in memory.\n",
    "\n",
    "3. Greedy Search:\\\n",
    "        - Time Complexity: O(b<sup>d</sup>) where b is branching factor and d is the maximum depth of the search space.\\\n",
    "        - Space Complexity: O(b<sup>d</sup>) because it stores all nodes in memory.\n",
    "\n",
    "4. A* Search:\\\n",
    "        - Time Complexity: O(b<sup>d</sup>) in the worst case, similar to BFS. In the worst case, Greedy search could explore almost all nodes, as it always expands the node that appears to be closest to the goal, based on the heuristic. However, it may take many wrong paths before finding the solution, similar to DFS.\\\n",
    "        - Space Complexity: O(b<sup>d</sup>) as well, due to storing nodes and costs in the priority queue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
